# yaml-language-server: $schema=https://carapace.sh/schemas/command.json
name: convert [SOURCE-SBOM] -o [FORMAT]
description: Convert between SBOM formats
flags:
    --catalogers*=: enable one or more package catalogers
    --exclude*=: exclude paths from being scanned using a glob expression
    --file=: file to write the default report output to (default is STDOUT)
    --name=: set the name of the target being analyzed
    --platform=: an optional platform specifier for container image sources (e.g. 'linux/arm64', 'linux/arm64/v8', 'arm64', 'linux')
    -o, --output*=: report output format, options=[syft-json cyclonedx-xml cyclonedx-json github-json spdx-tag-value spdx-json syft-table syft-text template]
    -s, --scope=: selection of layers to catalog, options=[Squashed AllLayers]
    -t, --template=: specify the path to a Go template file
documentation:
    command: '[AI] `syft convert` is a command used in Syft, an open-source tool for secure and efficient data transfer between cloud services and local machines. This specific command is utilized to convert a Syft manifest file from one format to another, such as from JSON to YAML or vice versa. The conversion ensures compatibility with different tools or configurations that may have varying preferences for the manifest file format.'
    flag:
        catalogers: '[AI] `syft convert --catalogers` is a command used in Syft data versioning tool. It converts the format of Syft catalog files, which store metadata about data versions, between different catalog formats. The `--catalogers` flag specifies the name(s) of the cataloger(s) whose catalogs will be converted. This command is useful when migrating from one cataloger to another or when upgrading Syft to a new version that uses a different catalog format.'
        exclude: '[AI] `syft convert --exclude` is a command in Syft data conversion tool used to exclude specific files or directories from being converted during the data syncing process. The `--exclude` option takes a list of glob patterns as arguments, and any files or directories that match those patterns will be skipped during the conversion process. This can be useful for excluding large or unnecessary files, or for preserving sensitive information that should not be synced between systems.'
        file: '[AI] The `syft convert --file` command is a part of Syft, an open-source tool for transferring Kubernetes secrets and other resources between clusters or environments. This specific command is used to convert the format of a file containing Syft YAML data into another desired format such as JSON or HCL. The `--file` flag indicates that the input data is in the form of a file instead of being piped from standard input.'
        name: |-
            [AI] The `syft convert` command is a tool in the Syft data transfer and transformation library for converting data formats between various systems, such as Hadoop Distributed File System (HDFS), Amazon S3, or Google Cloud Storage.

            The `--name` option is used to specify the name or label of the resulting converted object. It takes a required argument, which is a string that represents the desired name for the output file or object in the target system. This option helps keep track of the converted data and maintain a clear identification of each conversion job performed using Syft.
        output: '[AI] `syft convert` is a command-line tool in Syft, an open-source data transfer utility. The `--output` option specifies the output format for converted data. For instance, `syft convert --input file.parquet --output csv file.csv` converts Parquet files to CSV format. The converted data is written to the specified output file.'
        platform: '[AI] `syft convert` is a command-line tool in Syft, an open-source data transfer and serialization library developed by Microsoft for seamless transfer of Apache Spark RDDs between different environments, such as on-premises clusters and cloud services like Azure Databricks. The `--platform` flag specifies the target platform for converting serialized RDD data. This flag helps ensure that the transferred data is compatible with the specific version of Spark running in the receiving environment. For example, you can use `--platform spark:2.4.5` to convert data for Apache Spark 2.4.5.'
        scope: '[AI] `syft convert --scope` is a command used in Syft, an open-source tool for transporting Kubernetes objects between clusters. The `--scope` flag specifies the scope of the conversion operation. It can be set to `namespaced` or `clustered`, depending on whether you want to convert namespaced or clustered resources, respectively. Clustered resources are those that don''t have a namespace in Kubernetes, like ConfigMaps and Secrets.'
        template: '[AI] `syft convert --template` is a command in Syft, an open-source tool for transferring Kubernetes secrets and other data between clusters or environments. The `--template` option instructs Syft to generate an Ansible playbook template based on the given source YAML file. This can be useful when automating the conversion of Kubernetes resources between different versions or configurations. The resulting Ansible template can then be used to apply the changes in an Ansible environment.'
