# yaml-language-server: $schema=https://carapace.sh/schemas/command.json
name: autoscale (-f FILENAME | TYPE NAME | TYPE/NAME) [--min=MINPODS] --max=MAXPODS [--cpu-percent=CPU]
description: Auto-scale a deployment, replica set, stateful set, or replication controller
group: deploy
flags:
    --allow-missing-template-keys: If true, ignore any errors in templates when a field or map key is missing in the template. Only applies to golang and jsonpath output formats.
    --cpu-percent=: The target average CPU utilization (represented as a percent of requested CPU) over all the pods. If it's not specified or negative, a default autoscaling policy will be used.
    --dry-run?: Must be "none", "server", or "client". If client strategy, only print the object that would be sent, without sending it. If server strategy, submit server-side request without persisting the resource.
    --field-manager=: Name of the manager used to track field ownership.
    --max!=: The upper limit for the number of pods that can be set by the autoscaler. Required.
    --min=: The lower limit for the number of pods that can be set by the autoscaler. If it's not specified or negative, the server will apply a default value.
    --name=: The name for the newly created object. If not specified, the name of the input resource will be used.
    --record&: Record current kubectl command in the resource annotation. If set to false, do not record the command. If set to true, record the command. If not set, default to updating the existing annotation value only if one already exists.
    --save-config: If true, the configuration of current object will be saved in its annotation. Otherwise, the annotation will be unchanged. This flag is useful when you want to perform kubectl apply on this object in the future.
    --show-managed-fields: If true, keep the managedFields when printing objects in JSON or YAML format.
    --template=: Template string or path to template file to use when -o=go-template, -o=go-template-file. The template format is golang templates [http://golang.org/pkg/text/template/#pkg-overview].
    -R, --recursive: Process the directory used in -f, --filename recursively. Useful when you want to manage related manifests organized within the same directory.
    -f, --filename*=: Filename, directory, or URL to files identifying the resource to autoscale.
    -k, --kustomize=: Process the kustomization directory. This flag can't be used together with -f or -R.
    -o, --output=: 'Output format. One of: (json, yaml, name, go-template, go-template-file, template, templatefile, jsonpath, jsonpath-as-json, jsonpath-file).'
documentation:
    command: '[AI] `kubectl autoscale` is a Kubernetes command-line interface (CLI) tool used to automatically adjust the number of replicas for a specified Kubernetes deployment or replica set based on observed CPU utilization or other custom metrics. This helps maintain desired levels of performance and availability while minimizing resource wastage. The command requires specifying the resource, the minimum and maximum replicas, as well as optional target CPU utilization percentage. For instance: `kubectl autoscale deployment <deployment-name> --min=1 --max=5 --cpu-percent=80`'
    flag:
        allow-missing-template-keys: '[AI] `kubectl autoscale` is a Kubernetes command-line tool used to automate the process of scaling a Kubernetes application horizontally based on certain metrics or rules. The `--allow-missing-template-keys` flag allows for the deployment YAML file to have missing keys when creating or updating an autoscaling deployment. This means that even if some required fields are not present in the YAML file, Kubectl will still attempt to create or update the autoscaler. However, it''s important to note that this flag should be used with caution as missing keys can result in unexpected behavior and errors.'
        cpu-percent: '[AI] `kubectl autoscale` is a command in the Kubernetes toolkit used to automate the process of scaling a deployment based on observed CPU usage. The `--cpu-percent` flag specifies the average CPU utilization threshold for triggering an autoscaling event. When CPU usage averages above this value, the number of replicas will be increased, and when it falls below, the number of replicas will be decreased to maintain optimal resource utilization in a cluster.'
        dry-run: |-
            [AI] `kubectl autoscale --dry-run` is a command used with Kubernetes and `kubectl`, its command-line interface. This command triggers an operation to modify the autoscaling configuration of a Kubernetes deployment or replica set, without actually applying those changes to the cluster.

            The `--dry-run` flag instructs `kubectl` to print the changes that would be made if the command were executed with no flags. This is useful for reviewing proposed changes before making them live in production. It helps prevent unintended consequences or errors, and can serve as a learning tool for understanding how Kubernetes autoscaling works.
        field-manager: '[AI] `kubectl autoscale` is a command-line tool in Kubernetes used for managing and scaling Kubernetes resources, such as Pods or ReplicaSets. The `--field-manager` flag enables the use of Cluster Autoscaler''s custom controllers for managing node and pod autoscaling, allowing users to define custom metrics and behaviors for scaling their clusters. With this flag, you can create, update, and delete custom autoscaling policies based on specific metrics or custom logic, providing more control and flexibility over your Kubernetes environment.'
        filename: '[AI] `kubectl autoscale` is a command-line tool used to automate the scaling of Kubernetes applications. The option `--filename` is used to provide a YAML or JSON file that contains the configuration for the desired autoscaling behavior, such as the minimum and maximum number of replicas, or the metrics and thresholds to trigger scaling. For example, `kubectl autoscale deployment my-app --filename my-autoscaling-config.yaml`.'
        kustomize: '[AI] `kubectl autoscale` is a Kubernetes command-line tool used to automatically adjust the number of replicas in a deployment based on observed CPU or memory utilization. The `--kustomize` flag is an optional argument that allows the user to provide customizations to the autoscaling configuration using Kustomize. With `--kustomize`, you can apply patches, extensions, or custom resources to the autoscaling process before it''s applied to your cluster. This can be useful for modifying the autoscaler behavior, such as changing the metrics used for scaling or the minimum and maximum number of replicas.'
        max: '[AI] `kubectl autoscale` is a Kubernetes command-line tool used to automate the process of scaling a deployed application based on certain metrics or conditions. The `--max` flag sets the maximum number of replicas for a particular deployment or replica set. In other words, it specifies the upper limit for the number of instances of a pod that can run at any given time. This can be useful in preventing unnecessary resource usage or controlling costs in a production environment.'
        min: '[AI] `kubectl autoscale` is a Kubernetes command-line tool used to automatically adjust the number of replicas in a deployment based on specified metrics or conditions. The `--min` flag sets the minimum number of replicas for the deployment. This means that Kubernetes will not scale down the deployment below this minimum number, ensuring a certain level of availability for the application running in the deployment.'
        name: '[AI] `kubectl autoscale` is a command-line tool used to automate scaling of Kubernetes resources. The `--name` argument specifies the name or the selector of the Kubernetes resource (like Deployment, ReplicaSet, etc.) for which you want to enable autoscaling. Autoscaling allows Kubernetes to automatically adjust the number of replicas based on defined metrics and rules.'
        output: '[AI] `kubectl autoscale` is a command-line tool used to automate Kubernetes cluster resource scaling. The `--output` option specifies the format of the output from this command. For instance, `--output=json` returns the result in JSON format or `--output=yaml` for YAML. This helps in processing the output data using scripts or other automated tools. It does not change the actual scaling behavior itself but only affects the way the result of the scaling operation is displayed.'
        record: '[AI] `kubectl autoscale` is a command-line tool used for managing Kubernetes cluster resources with Kubernetes CLI (kubectl). The `--record` flag, when used with the `autoscale` command, indicates that changes made to the autoscaling configuration will be recorded but not applied immediately. Instead, they will be added to the pending changes queue and applied during the next rolling update or replacement of the Pods in the affected Deployment, ReplicaSet, or HorizontalPodAutoscaler. This allows for review and rollback if necessary before the actual scaling takes place.'
        recursive: '[AI] `kubectl autoscale --recursive` is a command used in Kubernetes to automatically adjust the number of replicas for multiple Kubernetes resources at once, including their contained pods, based on observed CPU or memory utilization. The `--recursive` flag instructs the command to apply this autoscaling policy recursively to all matching resources within a namespace. It is particularly useful when dealing with complex applications that consist of multiple interconnected components.'
        save-config: '[AI] `kubectl autoscale` is a command used in Kubernetes to automate the process of scaling Horizontal Pods based on specified metrics or custom rules. The `--save-config` flag saves the current autoscaling configuration of the managed Kubernetes resource as a YAML file named "autoscaling-<resource>.yaml" in the current working directory. This can be useful for version control or applying the same scaling configuration across multiple clusters or environments.'
        show-managed-fields: '[AI] `kubectl autoscale --show-managed-fields` is a command used in Kubernetes to view the managed fields of an existing Autoscaler resource, such as a Horizontal Pod Autoscaler or Cluster Autoscaler. Managed fields refer to the specific parts of the underlying Kubernetes objects that are managed by the autoscaler. These fields are modified automatically based on the autoscaling policy. By using `--show-managed-fields`, you can see which fields will be updated by the autoscaler when adjusting replicas, allowing you to understand the impact of scaling actions.'
        template: '[AI] `kubectl autoscale` is a Kubernetes command-line tool used to automate the process of scaling a Kubernetes application based on certain conditions. The `--template` option modifies the Kubernetes YAML manifests before applying them. This allows for dynamic adjustments to the templates, such as including variables or using conditionals, without having to manually modify each YAML file. With this option, users can define custom scaling policies and apply them consistently across their Kubernetes clusters.'
